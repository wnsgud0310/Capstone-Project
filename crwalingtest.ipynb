{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from selenium import webdriver\n",
    "from selenium.webdriver.common.keys import Keys\n",
    "from selenium.webdriver.common.by import By\n",
    "from selenium.webdriver.support.ui import WebDriverWait\n",
    "from selenium.webdriver.support import expected_conditions as EC\n",
    "from selenium.webdriver.chrome.service import Service\n",
    "from webdriver_manager.chrome import ChromeDriverManager\n",
    "from selenium.common.exceptions import TimeoutException, StaleElementReferenceException\n",
    "from selenium.common.exceptions import NoSuchElementException\n",
    "import pandas as pd \n",
    "import pyperclip\n",
    "import time\n",
    "\n",
    "\n",
    "\n",
    "# ì›¹ ë“œë¼ì´ë²„ ì„¤ì •\n",
    "driver = webdriver.Chrome(service=Service(ChromeDriverManager().install()))\n",
    "driver.get(\"https://nid.naver.com/nidlogin.login?mode=form&url=https%3A%2F%2Fwww.naver.com\")\n",
    "time.sleep(2)\n",
    "\n",
    "\n",
    "user_id = \"ffjjo0310\"\n",
    "user_pw = \"wnsgud800320\"\n",
    "\n",
    "# 2. ì•„ì´ë”” ì…ë ¥\n",
    "id = driver.find_element(By.CSS_SELECTOR, \"#id\")\n",
    "pyperclip.copy(user_id)\n",
    "id.send_keys(Keys.CONTROL, 'v')\n",
    "time.sleep(2)\n",
    "\n",
    "# 3. ë¹„ë°€ë²ˆí˜¸ ì…ë ¥\n",
    "pw = driver.find_element(By.CSS_SELECTOR, \"#pw\")\n",
    "pyperclip.copy(user_pw)\n",
    "pw.send_keys(Keys.CONTROL, 'v')\n",
    "time.sleep(2)\n",
    "\n",
    "# 4. ë¡œê·¸ì¸ ë²„íŠ¼ í´ë¦­\n",
    "driver.find_element(By.CSS_SELECTOR, \".btn_login\").click()\n",
    "\n",
    "# ë„¤ì´ë²„ ì¤‘ê³ ë‚˜ë¼ ì¹´í˜ ì ‘ì†\n",
    "driver.get(\"https://cafe.naver.com/joonggonara\")\n",
    "\n",
    "# íŠ¹ì • ë©”ë‰´(ì˜ˆ: 'ì „ì²´ ê¸€') í´ë¦­\n",
    "search_menu = WebDriverWait(driver, 10).until(\n",
    "    EC.element_to_be_clickable((By.CSS_SELECTOR, \"#menuLink339\"))\n",
    ")\n",
    "\n",
    "\n",
    "search_menu.click()\n",
    "\n",
    "# iframeìœ¼ë¡œ ì „í™˜\n",
    "driver.switch_to.frame(\"cafe_main\")\n",
    "\n",
    "# ê²€ìƒ‰ ë°•ìŠ¤ ì°¾ê¸°\n",
    "search_box = WebDriverWait(driver, 10).until(\n",
    "    EC.presence_of_element_located((By.ID, \"query\"))\n",
    ")\n",
    "\n",
    "# ê²€ìƒ‰ ë°•ìŠ¤ì— 'ì•„ì´í°' ì…ë ¥í•˜ê³  ì—”í„°í‚¤ ì…ë ¥\n",
    "search_box.send_keys(\"ì•„ì´í°\")\n",
    "search_box.send_keys(Keys.ENTER)\n",
    "\n",
    "# ëª©ë¡ í¬ê¸° ì„ íƒ\n",
    "list_size_button = WebDriverWait(driver, 10).until(\n",
    "    EC.element_to_be_clickable((By.ID, \"listSizeSelectDiv\"))\n",
    ")\n",
    "list_size_button.click()\n",
    "\n",
    "# \"50ê°œì”© ë³´ê¸°\" ì„ íƒ\n",
    "fifty_per_page_option = WebDriverWait(driver, 10).until(\n",
    "    EC.element_to_be_clickable((By.CSS_SELECTOR, \"#listSizeSelectDiv > ul > li:nth-child(7) > a\"))\n",
    ")\n",
    "fifty_per_page_option.click()\n",
    "\n",
    "\n",
    "# ê²€ìƒ‰ ì˜µì…˜ ë“œë¡­ë‹¤ìš´ ë©”ë‰´ í™œì„±í™”\n",
    "search_option_button = WebDriverWait(driver, 10).until(\n",
    "    EC.element_to_be_clickable((By.ID, \"searchOptionSelectDiv\"))\n",
    ")\n",
    "search_option_button.click()\n",
    "\n",
    "# \"ì•ˆì „ê±°ë˜\" ì„ íƒì„ ìœ„í•œ ëª…ì‹œì  ëŒ€ê¸°\n",
    "WebDriverWait(driver, 10).until(\n",
    "    EC.visibility_of_element_located((By.CSS_SELECTOR, \"#searchOptionSelectDiv > ul\"))\n",
    ")\n",
    "\n",
    "# \"ì•ˆì „ê±°ë˜\" ì„ íƒ\n",
    "safe_transaction_option = WebDriverWait(driver, 10).until(\n",
    "    EC.element_to_be_clickable((By.CSS_SELECTOR, \"#searchOptionSelectDiv > ul > li:nth-child(3) > a\"))\n",
    ")\n",
    "safe_transaction_option.click()\n",
    "\n",
    "\n",
    "\n",
    "data = []\n",
    "\n",
    "# í˜ì´ì§€ ì´ë™ ë¡œì§ ë° ë°ì´í„° ì¶”ì¶œ\n",
    "for page in range(1, 81):  # 1ë¶€í„° 80í˜ì´ì§€ê¹Œì§€\n",
    "    WebDriverWait(driver, 10).until(\n",
    "        EC.presence_of_element_located((By.CSS_SELECTOR, \".article\"))\n",
    "    )\n",
    "    num_posts = len(driver.find_elements(By.CSS_SELECTOR, \".article\"))\n",
    "    print(f\"Processing page {page} with {num_posts} posts...\")\n",
    "\n",
    "    for i in range(num_posts):\n",
    "        try:\n",
    "            # ë§¤ë²ˆ ìƒˆë¡œìš´ ìš”ì†Œë¥¼ ì°¾ì•„ í´ë¦­\n",
    "            post_links = WebDriverWait(driver, 10).until(\n",
    "                EC.presence_of_all_elements_located((By.CSS_SELECTOR, \".article\"))\n",
    "            )\n",
    "            driver.execute_script(\"arguments[0].click();\", post_links[i])\n",
    "\n",
    "            # ë°ì´í„° ì¶”ì¶œ\n",
    "            model_name = WebDriverWait(driver, 10).until(\n",
    "                EC.presence_of_element_located((By.CSS_SELECTOR, \".ProductName\"))\n",
    "            ).text\n",
    "            date = driver.find_element(By.CSS_SELECTOR, \".date\").text\n",
    "            price = driver.find_element(By.CSS_SELECTOR, \".ProductPrice\").text\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "               # ì˜ˆì™¸ ì²˜ë¦¬ ì¶”ê°€\n",
    "            try:\n",
    "                info = driver.find_element(By.CSS_SELECTOR, \".se-module.se-module-text\").text\n",
    "            except NoSuchElementException:\n",
    "                print(\"Info element not found, using default info.\")\n",
    "                info = \"No additional information available.\"\n",
    "\n",
    "\n",
    "\n",
    "            data.append([model_name, date, price, info])\n",
    "\n",
    "            # ë’¤ë¡œ ê°€ê¸°\n",
    "            driver.back()\n",
    "            WebDriverWait(driver, 10).until(\n",
    "                EC.frame_to_be_available_and_switch_to_it((By.ID, \"cafe_main\"))\n",
    "            )\n",
    "        except StaleElementReferenceException:\n",
    "            print(\"Element has become stale, retrying...\")\n",
    "            continue\n",
    "        except TimeoutException:\n",
    "            print(\"Time out while trying to access the post details.\")\n",
    "            continue\n",
    "\n",
    "    if page % 10 == 0:  # 10, 20, 30... í˜ì´ì§€ì—ì„œ ë‹¤ìŒ ë²„íŠ¼ í´ë¦­\n",
    "        try:\n",
    "            next_button = WebDriverWait(driver, 10).until(\n",
    "                EC.element_to_be_clickable((By.CSS_SELECTOR, \"#main-area > div.prev-next > a.pgR > span\"))\n",
    "            )\n",
    "            next_button.click()\n",
    "            print(f\"Moved to next set of pages after page {page}\")\n",
    "        except TimeoutException:\n",
    "            print(\"Time out while trying to click next button.\")\n",
    "            continue\n",
    "        except NoSuchElementException: # type: ignore\n",
    "            print(\"Next button not found. It might be the last page.\")\n",
    "            break\n",
    "\n",
    "    # ë‹¤ìŒ í˜ì´ì§€ë¡œ ì´ë™\n",
    "    try:\n",
    "        WebDriverWait(driver, 10).until(\n",
    "            EC.presence_of_element_located((By.LINK_TEXT, str(page + 1)))\n",
    "        ).click()\n",
    "        print(f\"Moved to page {page + 1}\")\n",
    "    except TimeoutException:\n",
    "        print(\"Time out while trying to navigate to the next page.\")\n",
    "        break\n",
    "\n",
    "# ë°ì´í„° ì €ì¥\n",
    "df = pd.DataFrame(data, columns=['Model Name', 'Date', 'Price', 'Information'])\n",
    "df.to_csv('iphone_data.csv', index=False, encoding='utf-8-sig')\n",
    "\n",
    "# ì›¹ ë“œë¼ì´ë²„ ì¢…ë£Œ\n",
    "driver.quit()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ì›ë³¸ ë°ì´í„°ì˜ í–‰ ìˆ˜: 4000\n",
      "ì¤‘ë³µ ì œê±° í›„ì˜ í–‰ ìˆ˜: 2043\n",
      "ì¤‘ë³µ ì œê±°ëœ ë°ì´í„°ê°€ 'iphone_data_cleaned.csv' íŒŒì¼ë¡œ ì €ì¥ë˜ì—ˆìŠµë‹ˆë‹¤.\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# CSV íŒŒì¼ ë¶ˆëŸ¬ì˜¤ê¸°\n",
    "df = pd.read_csv('iphone_data.csv')\n",
    "\n",
    "# ë°ì´í„° ì¤‘ë³µ í™•ì¸\n",
    "print(\"ì›ë³¸ ë°ì´í„°ì˜ í–‰ ìˆ˜:\", len(df))\n",
    "print(\"ì¤‘ë³µ ì œê±° í›„ì˜ í–‰ ìˆ˜:\", df.drop_duplicates().shape[0])\n",
    "\n",
    "# ì¤‘ë³µëœ í–‰ ì œê±°\n",
    "df_cleaned = df.drop_duplicates()\n",
    "\n",
    "# ì¤‘ë³µ ì œê±°ëœ ë°ì´í„°ë¥¼ ìƒˆë¡œìš´ CSV íŒŒì¼ë¡œ ì €ì¥\n",
    "df_cleaned.to_csv('iphone_data_cleaned.csv', index=False, encoding='utf-8-sig')\n",
    "\n",
    "print(\"ì¤‘ë³µ ì œê±°ëœ ë°ì´í„°ê°€ 'iphone_data_cleaned.csv' íŒŒì¼ë¡œ ì €ì¥ë˜ì—ˆìŠµë‹ˆë‹¤.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ëª¨ë¸ëª…ì— 'ì•„ì´í°' ë˜ëŠ” 'iphone'ì´ ë“¤ì–´ê°€ì§€ ì•Šì€ í–‰ì„ ì œê±°í•˜ê³  'iphone_data_filtered.csv' íŒŒì¼ë¡œ ì €ì¥ë˜ì—ˆìŠµë‹ˆë‹¤.\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# CSV íŒŒì¼ ë¶ˆëŸ¬ì˜¤ê¸°\n",
    "df = pd.read_csv('iphone_data.csv')\n",
    "\n",
    "# 'Model Name' ì»¬ëŸ¼ì—ì„œ 'ì•„ì´í°' ë˜ëŠ” 'iphone'ì´ í¬í•¨ëœ í–‰ë§Œ ìœ ì§€\n",
    "df_filtered = df[df['Model Name'].str.contains('ì•„ì´í°|iphone', case=False, na=False)]\n",
    "\n",
    "# í•„í„°ë§ëœ ë°ì´í„°ë¥¼ ìƒˆë¡œìš´ CSV íŒŒì¼ë¡œ ì €ì¥\n",
    "df_filtered.to_csv('iphone_data_filtered.csv', index=False, encoding='utf-8-sig')\n",
    "\n",
    "print(\"ëª¨ë¸ëª…ì— 'ì•„ì´í°' ë˜ëŠ” 'iphone'ì´ ë“¤ì–´ê°€ì§€ ì•Šì€ í–‰ì„ ì œê±°í•˜ê³  'iphone_data_filtered.csv' íŒŒì¼ë¡œ ì €ì¥ë˜ì—ˆìŠµë‹ˆë‹¤.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ì •ë³´ì—ì„œ ë¶ˆí•„ìš”í•œ í…ìŠ¤íŠ¸ë¥¼ ì œê±°í•˜ê³  'iphone_data_1.csv' íŒŒì¼ë¡œ ì €ì¥ë˜ì—ˆìŠµë‹ˆë‹¤.\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# CSV íŒŒì¼ ë¶ˆëŸ¬ì˜¤ê¸°\n",
    "df = pd.read_csv('iphone_data.csv')\n",
    "\n",
    "# ì œê±°í•  í…ìŠ¤íŠ¸ ì •ì˜\n",
    "remove_text1 = \"ğŸ“¢ ì œëª©ì— \\\"ì œì¡°ì‚¬/ ë¸Œëœë“œ ëª…\\\"ê³¼ â€œìƒí’ˆëª…(ex. ê°¤ëŸ­ì‹œ S11) â€ì„ ë„£ì–´ ì‘ì„±í•˜ë©´, ë³´ë‹¤ ë¹ ë¥¸ íŒë§¤ê°€ ê°€ëŠ¥í•©ë‹ˆë‹¤!\"\n",
    "remove_text2 = \"ğŸ“¢ ê²Œì‹œê¸€ ì‘ì„± ì‹œ ë°°ì†¡ ë°©ë²•ì— â€œì§ê±°ë˜â€ì™€ â€œë‚´ ìœ„ì¹˜â€ ì„¤ì •í•  ê²½ìš°, ë³´ë‹¤ ë¹ ë¥¸ íŒë§¤ê°€ ê°€ëŠ¥í•©ë‹ˆë‹¤!\"\n",
    "remove_text3 = \"â€» ë“±ë¡í•œ ê²Œì‹œê¸€ì´ íšŒì›ì˜ ì‹ ê³ ë¥¼ ë°›ê±°ë‚˜ ì´ìƒê±°ë˜ë¡œ ëª¨ë‹ˆí„°ë§ ë  ê²½ìš° ì¤‘ê³ ë‚˜ë¼ ì‚¬ê¸°í†µí•©ì¡°íšŒ DBë¡œ ìˆ˜ì§‘/í™œìš©ë  ìˆ˜ ìˆìŠµë‹ˆë‹¤.\"\n",
    "\n",
    "\n",
    "# 'Information' ì»¬ëŸ¼ì—ì„œ ì§€ì •í•œ í…ìŠ¤íŠ¸ ì œê±°\n",
    "df['Information'] = df['Information'].str.replace(remove_text1, '', regex=False)\n",
    "df['Information'] = df['Information'].str.replace(remove_text2, '', regex=False)\n",
    "df['Information'] = df['Information'].str.replace(remove_text3, '', regex=False)\n",
    "# ì •ë¦¬ëœ ë°ì´í„°ë¥¼ ìƒˆë¡œìš´ CSV íŒŒì¼ë¡œ ì €ì¥\n",
    "df.to_csv('iphone_data_final.csv', index=False, encoding='utf-8-sig')\n",
    "\n",
    "print(\"ì •ë³´ì—ì„œ ë¶ˆí•„ìš”í•œ í…ìŠ¤íŠ¸ë¥¼ ì œê±°í•˜ê³  'iphone_data_final.csv' íŒŒì¼ë¡œ ì €ì¥ë˜ì—ˆìŠµë‹ˆë‹¤.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import re\n",
    "\n",
    "def load_and_preprocess_data(file_path):\n",
    "    # ë°ì´í„° ë¡œë“œ\n",
    "    data = pd.read_csv(file_path)\n",
    "\n",
    "    # 'Date' ì¹¼ëŸ¼ì„ datetime ê°ì²´ë¡œ ë³€í™˜\n",
    "    data['Date'] = pd.to_datetime(data['Date'], format='%Y.%m.%d. %H:%M')\n",
    "\n",
    "    # 'Price' ì¹¼ëŸ¼ì—ì„œ ìˆ«ìë§Œ ì¶”ì¶œí•˜ì—¬ ì •ìˆ˜í˜•ìœ¼ë¡œ ë³€í™˜\n",
    "    data['Price'] = data['Price'].str.replace('ì›', '').str.replace(',', '').astype(int)\n",
    "\n",
    "    # 'Capacity' ì •ë³´ ì¶”ì¶œ\n",
    "    def extract_capacity(text):\n",
    "        match = re.search(r'(\\d+(GB|G|ê¸°ê°€))\\b', text)\n",
    "        if match:\n",
    "            return match.group(1)\n",
    "        return 'Unknown'\n",
    "\n",
    "    data['Capacity'] = data['Information'].astype(str).apply(extract_capacity)\n",
    "\n",
    "    return data\n",
    "\n",
    "def save_data(data, save_path):\n",
    "    # ë°ì´í„°ë¥¼ UTF-8 ì¸ì½”ë”©ìœ¼ë¡œ CSV íŒŒì¼ë¡œ ì €ì¥\n",
    "    data.to_csv(save_path, index=False, encoding='utf-8')\n",
    "\n",
    "# ì‚¬ìš© ì˜ˆ\n",
    "file_path = 'path_to_your_data.csv'  # ë°ì´í„° íŒŒì¼ ê²½ë¡œ\n",
    "processed_save_path = 'path_to_save_processed_data.csv'  # ì €ì¥í•  íŒŒì¼ ê²½ë¡œ\n",
    "\n",
    "data = load_and_preprocess_data(file_path)\n",
    "save_data(data, processed_save_path)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import re\n",
    "\n",
    "def load_and_preprocess_data(file_path):\n",
    "    # ë°ì´í„° ë¡œë“œ\n",
    "    data = pd.read_csv(file_path)\n",
    "\n",
    "    # 'Date' ì¹¼ëŸ¼ì„ datetime ê°ì²´ë¡œ ë³€í™˜\n",
    "    data['Date'] = pd.to_datetime(data['Date'], format='%Y.%m.%d. %H:%M')\n",
    "\n",
    "    # 'Price' ì¹¼ëŸ¼ì—ì„œ ìˆ«ìë§Œ ì¶”ì¶œí•˜ì—¬ ì •ìˆ˜í˜•ìœ¼ë¡œ ë³€í™˜\n",
    "    data['Price'] = data['Price'].str.replace('ì›', '').str.replace(',', '').astype(int)\n",
    "\n",
    "    # 'Capacity' ì •ë³´ ì¶”ì¶œ\n",
    "    def extract_capacity(text):\n",
    "        match = re.search(r'(\\d+(GB|G|ê¸°ê°€))\\b', text)\n",
    "        if match:\n",
    "            return match.group(1)\n",
    "        return 'Unknown'\n",
    "\n",
    "    data['Capacity'] = data['Information'].astype(str).apply(extract_capacity)\n",
    "\n",
    "    return data\n",
    "\n",
    "def save_data(data, save_path):\n",
    "    # ë°ì´í„°ë¥¼ UTF-8 ì¸ì½”ë”©ìœ¼ë¡œ CSV íŒŒì¼ë¡œ ì €ì¥\n",
    "    data.to_csv(save_path, index=False, encoding='utf-8')\n",
    "\n",
    "# ì‚¬ìš© ì˜ˆ\n",
    "file_path = r'C:\\startcoding\\python_crawling\\Capstone\\iphone_data_final.csv'  # ë°ì´í„° íŒŒì¼ ê²½ë¡œ\n",
    "processed_save_path = r'C:\\startcoding\\python_crawling\\Capstone\\processed_iphone_data.csv'  # ì €ì¥í•  íŒŒì¼ ê²½ë¡œ\n",
    "\n",
    "data = load_and_preprocess_data(file_path)\n",
    "save_data(data, processed_save_path)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ERROR: Could not open requirements file: [Errno 2] No such file or directory: 'requirements.txt'\n"
     ]
    }
   ],
   "source": [
    "pip install -r requirements.txt\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
